{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoEY9RrUM6BesVDZo/CpQx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KalpanadeviGunasekaran/CNN_Architecture/blob/main/Digit_Mnist_Alexnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "# Define the modified AlexNet architecture for MNIST\n",
        "class ModifiedAlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ModifiedAlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((5, 5))  # Adjusted for smaller input size\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 5 * 5, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = ModifiedAlexNet(num_classes=10)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}')\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Test Accuracy: {100 * accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdA_HqpvYO00",
        "outputId": "cd067141-a1aa-4432-df4c-b83d206c6b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 123870691.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 88939569.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 37017424.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 22203413.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch 1/5, Batch 0/938, Loss: 2.304239273071289\n",
            "Epoch 1/5, Batch 100/938, Loss: 2.297402858734131\n",
            "Epoch 1/5, Batch 200/938, Loss: 2.3097751140594482\n",
            "Epoch 1/5, Batch 300/938, Loss: 2.2987563610076904\n",
            "Epoch 1/5, Batch 400/938, Loss: 2.2957561016082764\n",
            "Epoch 1/5, Batch 500/938, Loss: 2.0792577266693115\n",
            "Epoch 1/5, Batch 600/938, Loss: 1.421702265739441\n",
            "Epoch 1/5, Batch 700/938, Loss: 0.70811927318573\n",
            "Epoch 1/5, Batch 800/938, Loss: 0.3705872595310211\n",
            "Epoch 1/5, Batch 900/938, Loss: 0.28576746582984924\n",
            "Epoch 2/5, Batch 0/938, Loss: 0.16845613718032837\n",
            "Epoch 2/5, Batch 100/938, Loss: 0.18879461288452148\n",
            "Epoch 2/5, Batch 200/938, Loss: 0.15881741046905518\n",
            "Epoch 2/5, Batch 300/938, Loss: 0.030397646129131317\n",
            "Epoch 2/5, Batch 400/938, Loss: 0.10003094375133514\n",
            "Epoch 2/5, Batch 500/938, Loss: 0.1301264464855194\n",
            "Epoch 2/5, Batch 600/938, Loss: 0.023921191692352295\n",
            "Epoch 2/5, Batch 700/938, Loss: 0.1185169667005539\n",
            "Epoch 2/5, Batch 800/938, Loss: 0.24942423403263092\n",
            "Epoch 2/5, Batch 900/938, Loss: 0.09987511485815048\n",
            "Epoch 3/5, Batch 0/938, Loss: 0.11871680617332458\n",
            "Epoch 3/5, Batch 100/938, Loss: 0.10114883631467819\n",
            "Epoch 3/5, Batch 200/938, Loss: 0.07688922435045242\n",
            "Epoch 3/5, Batch 300/938, Loss: 0.018465254455804825\n",
            "Epoch 3/5, Batch 400/938, Loss: 0.09237541258335114\n",
            "Epoch 3/5, Batch 500/938, Loss: 0.07711846381425858\n",
            "Epoch 3/5, Batch 600/938, Loss: 0.11842329800128937\n",
            "Epoch 3/5, Batch 700/938, Loss: 0.001286130747757852\n",
            "Epoch 3/5, Batch 800/938, Loss: 0.02621709182858467\n",
            "Epoch 3/5, Batch 900/938, Loss: 0.03691903501749039\n",
            "Epoch 4/5, Batch 0/938, Loss: 0.003004759084433317\n",
            "Epoch 4/5, Batch 100/938, Loss: 0.021701306104660034\n",
            "Epoch 4/5, Batch 200/938, Loss: 0.0750252828001976\n",
            "Epoch 4/5, Batch 300/938, Loss: 0.11500172317028046\n",
            "Epoch 4/5, Batch 400/938, Loss: 0.07349478453397751\n",
            "Epoch 4/5, Batch 500/938, Loss: 0.02519056387245655\n",
            "Epoch 4/5, Batch 600/938, Loss: 0.008341223001480103\n",
            "Epoch 4/5, Batch 700/938, Loss: 0.03163605555891991\n",
            "Epoch 4/5, Batch 800/938, Loss: 0.010180041193962097\n",
            "Epoch 4/5, Batch 900/938, Loss: 0.11935582011938095\n",
            "Epoch 5/5, Batch 0/938, Loss: 0.0026168394833803177\n",
            "Epoch 5/5, Batch 100/938, Loss: 0.026756541803479195\n",
            "Epoch 5/5, Batch 200/938, Loss: 0.004198005422949791\n",
            "Epoch 5/5, Batch 300/938, Loss: 0.009009188041090965\n",
            "Epoch 5/5, Batch 400/938, Loss: 0.012166155502200127\n",
            "Epoch 5/5, Batch 500/938, Loss: 0.037245605140924454\n",
            "Epoch 5/5, Batch 600/938, Loss: 0.2973995804786682\n",
            "Epoch 5/5, Batch 700/938, Loss: 0.008131111040711403\n",
            "Epoch 5/5, Batch 800/938, Loss: 0.0018476685509085655\n",
            "Epoch 5/5, Batch 900/938, Loss: 0.01744571141898632\n",
            "Test Accuracy: 98.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MMAaP1aTYcmJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}